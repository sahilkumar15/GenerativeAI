{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For creating RAG application\n",
    "\n",
    "1. DATA\n",
    "2. Embedding Model\n",
    "3. DATA BASE\n",
    "4. PROMPT\n",
    "5. LLM\n",
    "\n",
    "Connect all the things\n",
    "\n",
    "1. huggingface hub using hf token(inferencing)\n",
    "2. load the model in local memory from the hugging face(finetune)\n",
    "\n",
    "here lots of memory is requierd(7b,10b,50b,100b)\n",
    "\n",
    "bitandbytes\n",
    "\n",
    "\n",
    "3. GGML(GPT-Generated Model Language), GGUF(GPT-Generated Unified Format)\n",
    "\n",
    "4. OLAMAM,LLAMA-CPP,LM-STUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "# from llama_index.llms import HuggingFaceLLM \n",
    "# from llama_index.prompts.prompts import SimpleInputPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OPENAI_API_KEY\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)\n",
    "\n",
    "# Retrieve the WEAVIATE_API_KEY \n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "# print(WEAVIATE_API_KEY)\n",
    "\n",
    "# Retrieve the WEAVIATE_CLUSTER link\n",
    "WEAVIATE_CLUSTER = os.getenv(\"WEAVIATE_CLUSTER\")\n",
    "# print(WEAVIATE_CLUSTER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(url= WEAVIATE_CLUSTER, auth_client_secret= weaviate.AuthApiKey(WEAVIATE_API_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=SimpleDirectoryReader(r'D:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\data')\n",
    "documents=loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
