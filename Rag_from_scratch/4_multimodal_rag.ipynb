{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Rag\n",
    "\n",
    "1. llamaindex framework\n",
    "2. Lancedb\n",
    "3. LLM model(GPT-4V)\n",
    "4. GEMINI-PRO-VISION\n",
    "\n",
    "Steps:\n",
    "1. Download video from YouTube, process and store it.\n",
    "\n",
    "2. Build Multi-Modal index and vector store for both texts and images.\n",
    "\n",
    "3. Retrieve relevant images and context, use both to augment the prompt.\n",
    "\n",
    "4. Using GPT4V for reasoning the correlations between the input query and augmented data and generating final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "import speech_recognition as sr\n",
    "from pytube import YouTube\n",
    "from pprint import pprint\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OPENAI_API_KEY\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\iNeuron\\\\GenAI\\\\GenerativeAI\\\\Rag_from_scratch'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Video Path: d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\video_data\n",
      "Output Folder: d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\mixed_data\n",
      "Output Audio Path: d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\mixed_data\\output_audio.wav\n",
      "Filepath: d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\video_data\\input_vid.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define the base path where you want to store everything\n",
    "base_path = Path(os.getcwd())\n",
    "\n",
    "# Define the subdirectories you need to create\n",
    "video_url=\"https://youtu.be/3dhcmeOTZ_Q\"\n",
    "output_video_path = base_path / \"video_data\"\n",
    "output_folder = base_path / \"mixed_data\"\n",
    "output_audio_path = base_path / \"mixed_data/output_audio.wav\"\n",
    "\n",
    "# Create the directories if they don't already exist\n",
    "output_video_path.mkdir(parents=True, exist_ok=True)\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the filepath for the input video\n",
    "filepath = output_video_path / \"input_vid.mp4\"\n",
    "\n",
    "# Print the paths to verify\n",
    "print(f\"Output Video Path: {output_video_path}\")\n",
    "print(f\"Output Folder: {output_folder}\")\n",
    "print(f\"Output Audio Path: {output_audio_path}\")\n",
    "print(f\"Filepath: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(image_path):\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for img_path in image_path:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "            \n",
    "            plt.subplot(2, 2, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "            images_shown += 1\n",
    "            if images_shown >= 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_url, output_path):\n",
    "    yt = YouTube(video_url)\n",
    "    metadata = {\"Author\": yt.author, \"Title\": yt.title, \"Views\": yt.views}\n",
    "    yt.streams.get_highest_resolution().download(output_path=output_path, filename=\"input_vid.mp4\")# filename=yt.title+\".mp4\") #\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "# Function to convert video to images\n",
    "def video_to_images(video_path, output_path):\n",
    "    clip = VideoFileClip(str(video_path))  # Convert Path to string\n",
    "    clip.write_images_sequence(\n",
    "        os.path.join(str(output_path), \"frame_%04d.png\"), fps=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_audio(video_path, output_audio_path):\n",
    "    clip = VideoFileClip(str(video_path))  # Convert Path to string\n",
    "    audio=clip.audio\n",
    "    audio.write_audiofile(str(output_audio_path))\n",
    "    return audio\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio_path):\n",
    "    recogniser = sr.Recognizer()\n",
    "    audio = sr.AudioFile(str(audio_path))\n",
    "    \n",
    "    with audio as source:\n",
    "        audio_data = recogniser.record(source)\n",
    "        try:\n",
    "            # recognise the speech\n",
    "            text = recogniser.recognize_whisper(audio_data)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Speech Recognition could not understand audio\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import speech_recognition as sr\n",
    "# from pathlib import Path\n",
    "\n",
    "# def audio_to_text(audio_path, output_folder):\n",
    "#     # Initialize the recognizer\n",
    "#     recogniser = sr.Recognizer()\n",
    "    \n",
    "#     # Ensure the output folder exists\n",
    "#     output_folder_path = Path(output_folder)\n",
    "#     output_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # Load the audio file\n",
    "#     audio = sr.AudioFile(str(audio_path))\n",
    "    \n",
    "#     with audio as source:\n",
    "#         # Adjust for ambient noise and record\n",
    "#         recogniser.adjust_for_ambient_noise(source)\n",
    "#         audio_data = recogniser.record(source)\n",
    "        \n",
    "#         try:\n",
    "#             # Use Google's web speech API to recognize the speech\n",
    "#             text = recogniser.recognize_google(audio_data)\n",
    "#             print(\"Recognized text:\", text)\n",
    "            \n",
    "#             # Write to file\n",
    "#             output_file_path = output_folder_path / \"recognized_text.txt\"\n",
    "#             with open(output_file_path, 'w') as file:\n",
    "#                 file.write(text)\n",
    "#             print(f\"Text successfully written to {output_file_path}\")\n",
    "                \n",
    "#         except sr.UnknownValueError:\n",
    "#             print(\"Speech Recognition could not understand audio\")\n",
    "#             text = \"Speech Recognition could not understand audio\"\n",
    "        \n",
    "#         except sr.RequestError as e:\n",
    "#             print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "#             text = f\"Error: {e}\"\n",
    "        \n",
    "#         # Write any error messages or blank responses to the file as well\n",
    "#         if text not in [\"\", \"Speech Recognition could not understand audio\"]:\n",
    "#             with open(output_file_path, 'w') as file:\n",
    "#                 file.write(text)\n",
    "    \n",
    "#     return text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://youtu.be/3dhcmeOTZ_Q'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/iNeuron/GenAI/GenerativeAI/Rag_from_scratch/video_data')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Author': '3-Minute Data Science',\n",
       " 'Title': 'Linear Regression in 3 Minutes',\n",
       " 'Views': 7829}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_vid = download_video(video_url, output_video_path)\n",
    "metadata_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/iNeuron/GenAI/GenerativeAI/Rag_from_scratch/video_data/input_vid.mp4')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/iNeuron/GenAI/GenerativeAI/Rag_from_scratch/mixed_data')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Writing frames d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\mixed_data\\frame_%04d.png.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done writing frames d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\mixed_data\\frame_%04d.png.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video_to_images(filepath,output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\mixed_data\\output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<moviepy.audio.io.AudioFileClip.AudioFileClip at 0x186121acc10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_to_audio(filepath,output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data=audio_to_text(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Lanyard regression is a statistical technique for modeling the relationship between an output variable and one or more input variables. In layman's terms, think of it as fitting a line through some data points as shown here, so you can make predictions on unknown data, assuming there is a linear relationship between the variables. You might be familiar with the linear function y equals mx plus b, where y is the output variable, also called the dependent variable. You may also see expressed as f of x, the function of the input variable. x on the other hand, would serve as the input variable, also called the independent variable. It's likely you'll see the coefficients m and b expressed as beta 1 and beta 0 respectively. So what do the m and b coefficients do? The m or beta 1 coefficient controls the slope of the line. The b or the beta 0 controls the intercept of the line. In machine learning, we also know it as the bias. These two coefficients are what we are solving for in linear regression. We can also extend to multiple input variables, so x1, x2, x3, with beta 1, beta 2, and beta 3, and so on, acting as slopes for each of those variables. In these higher dimensions, you would visualize the linear regression as a hyperplane. So how do we fit the line to these points? Well, you'll notice that there's these differences between the points and the line, these little red segments, these are called residuals. They are the differences between the data points and the predictions the line would produce. Take each of these residuals and square them. These are the squared errors, and notice that the large of the residuals are, the more amplified area of the squares are. If we total the areas of all of these squares for a given line, we will get the sum of the squared error, and this is known as our loss function. We need to find the beta 0 and beta 1 coefficients that will minimize that sum of squared error. The coefficients can be solved with a variety of techniques ranging from matrix decomposition to gradient descent, which is depicted right here. Thankfully, a lot of libraries are available to do this for us, and we will deep dive into these topics in other videos. To validate a linear regression, there are a number of techniques. Machine learning practitioners will often take a third of the data and put it into the test data set. The remaining two thirds will become the training data set. The training data set will then be used to fit the regression line. The test data set will then be used to validate the regression line. This is done to make sure that the regression performs well on data it has not seen before. The tricks used to evaluate the linear regression vary from the R square, standard error of the estimate, prediction intervals, as well as statistical significance. These are topics we will cover in future videos. If you enjoyed this video, please like and subscribe. Look at my two O'Reilly books, Essential Math for Data Science, and getting started with SQL. Chapter five of Essential Math for Data Science actually covers linear regression and much more depth. If you want live instruction, I also do teach on the O'Reilly platform. Promotional link below. I teach classes including machine learning from scratch, probability, and SQL. Comment on what topics you would like to see next, and I will see you again on 3 Minute Data Science.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text successfully written to d:\\iNeuron\\GenAI\\GenerativeAI\\Rag_from_scratch\\video_data\\recognized_text.txt\n"
     ]
    }
   ],
   "source": [
    "# Write to file\n",
    "output_file_path = output_video_path / \"recognized_text.txt\"\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(text_data)\n",
    "print(f\"Text successfully written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
